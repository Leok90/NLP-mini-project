{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"텍스트 감정분석.ipynb","provenance":[],"authorship_tag":"ABX9TyMED7HMZ96dko4Tb1VOO99w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hp4PLleqr8q","executionInfo":{"status":"ok","timestamp":1611748044956,"user_tz":-540,"elapsed":833,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"c170b7ae-6010-4125-a400-b9e951f9328c"},"source":["# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.`\r\n","sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\r\n","# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.`\r\n","word_list = 'i feel hungry'.split()\r\n","print(word_list)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["['i', 'feel', 'hungry']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQpLuzJpqyPU","executionInfo":{"status":"ok","timestamp":1611748096308,"user_tz":-540,"elapsed":530,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"36e71b21-b7f3-4472-f062-54c8a58b4c7e"},"source":["index_to_word={}  # 빈 딕셔너리를 만들어서\r\n","# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \r\n","# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \r\n","index_to_word[0]='<PAD>'  # 패딩용 단어\r\n","index_to_word[1]='<BOS>'  # 문장의 시작지점\r\n","index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\r\n","index_to_word[3]='i'\r\n","index_to_word[4]='feel'\r\n","index_to_word[5]='hungry'\r\n","index_to_word[6]='eat'\r\n","index_to_word[7]='lunch'\r\n","index_to_word[8]='now'\r\n","index_to_word[9]='happy'\r\n","print(index_to_word)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIFhbOuGrDbq","executionInfo":{"status":"ok","timestamp":1611748115844,"user_tz":-540,"elapsed":794,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"4d39ce70-911e-4a28-b9be-d0dfbc2ed4f1"},"source":["word_to_index={word:index for index, word in index_to_word.items()}\r\n","print(word_to_index)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3MbyoHbGrIIy","executionInfo":{"status":"ok","timestamp":1611748127212,"user_tz":-540,"elapsed":797,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"21e0fc64-0755-4358-f6e0-e826c7bac99a"},"source":["print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."],"execution_count":5,"outputs":[{"output_type":"stream","text":["4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-H4WRmHrK6T","executionInfo":{"status":"ok","timestamp":1611748133215,"user_tz":-540,"elapsed":788,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"5dd77033-f119-483c-e01d-25186fa331c8"},"source":["# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\r\n","# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \r\n","def get_encoded_sentence(sentence, word_to_index):\r\n","    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\r\n","print(get_encoded_sentence('i eat lunch', word_to_index))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[1, 3, 6, 7]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4Mp4mAErMYT","executionInfo":{"status":"ok","timestamp":1611748145069,"user_tz":-540,"elapsed":791,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"bf2d6029-2d8c-4e7e-e6b9-7aa9b03b6c9c"},"source":["# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \r\n","def get_encoded_sentences(sentences, word_to_index):\r\n","    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\r\n","\r\n","# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \r\n","encoded_sentences = get_encoded_sentences(sentences, word_to_index)\r\n","print(encoded_sentences)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpfsmUJ-rPRb","executionInfo":{"status":"ok","timestamp":1611748196420,"user_tz":-540,"elapsed":768,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"a82baedb-6ed6-47bd-860e-2c268c8ba942"},"source":["# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \r\n","def get_decoded_sentence(encoded_sentence, index_to_word):\r\n","    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\r\n","print(get_decoded_sentence([1, 3, 4, 5], index_to_word))\r\n","\r\n","# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \r\n","def get_decoded_sentences(encoded_sentences, index_to_word):\r\n","    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\r\n","\r\n","# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\r\n","print(get_decoded_sentences(encoded_sentences, index_to_word))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["i feel hungry\n","['i feel hungry', 'i eat lunch', 'now i feel happy']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvqaQHHjrb0E","executionInfo":{"status":"ok","timestamp":1611748345534,"user_tz":-540,"elapsed":966,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"7ca02777-e9e6-4cda-9a18-01a347bfa569"},"source":["import numpy as np\r\n","import tensorflow as tf\r\n","vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\r\n","word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정합니다.\r\n","embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\r\n","# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \r\n","# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \r\n","raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\r\n","raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\r\n","                                                       value=word_to_index['<PAD>'],\r\n","                                                       padding='post',\r\n","                                                       maxlen=5)\r\n","output = embedding(raw_inputs)\r\n","print(output)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[ 0.04672689  0.04139343 -0.03654686  0.02673781]\n","  [ 0.01315116 -0.03266656 -0.00410061  0.01520175]\n","  [ 0.04987461  0.0215382   0.04091934 -0.02450879]\n","  [ 0.00246093  0.04123416  0.01970449  0.03091618]\n","  [-0.02691009  0.03101857  0.02340641  0.03035941]]\n","\n"," [[ 0.04672689  0.04139343 -0.03654686  0.02673781]\n","  [ 0.01315116 -0.03266656 -0.00410061  0.01520175]\n","  [-0.03221266  0.04355602 -0.02401181 -0.02139371]\n","  [-0.01934824  0.04126415  0.02399665 -0.01281419]\n","  [-0.02691009  0.03101857  0.02340641  0.03035941]]\n","\n"," [[ 0.04672689  0.04139343 -0.03654686  0.02673781]\n","  [-0.009686   -0.03135655  0.00285488 -0.0173926 ]\n","  [ 0.01315116 -0.03266656 -0.00410061  0.01520175]\n","  [ 0.04987461  0.0215382   0.04091934 -0.02450879]\n","  [ 0.03731764 -0.02726763  0.03700212  0.01235963]]], shape=(3, 5, 4), dtype=float32)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxx4KI5MrpUE","executionInfo":{"status":"ok","timestamp":1611749160566,"user_tz":-540,"elapsed":764,"user":{"displayName":"Seyong Kim","photoUrl":"","userId":"10279459406240240497"}},"outputId":"fde98b9a-dc8c-413c-f950-9391c445bf4d"},"source":["# vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\r\n","word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \r\n","model = keras.Sequential()\r\n","model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\r\n","model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\r\n","model.add(keras.layers.Dense(8, activation='relu'))\r\n","model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\r\n","model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, None, 4)           40        \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 8)                 416       \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 72        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 9         \n","=================================================================\n","Total params: 537\n","Trainable params: 537\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aTbiKHzzvHMu"},"source":[""],"execution_count":null,"outputs":[]}]}